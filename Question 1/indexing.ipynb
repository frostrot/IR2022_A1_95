{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigram Inverted Index\n",
    "\n",
    "To create Unigram Inverted Index, the preprocessed documents will be parsed. The files are arranged alphabetically by title and given a number ID starting at 0. **doc_id.pkl** is a file that stores the Doc IDs to Doc Name mapping. The keywords are sorted in alphabetical order and posting lists are made for them. **index.pkl** is the name of the index that was produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./pickle_files/docs.pkl\",\"rb\") as f:\n",
    "    data = pkl.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collecting all the posting\n",
    "\n",
    "docs = {}\n",
    "posting = {}\n",
    "\n",
    "for i,files in enumerate(data):\n",
    "    docs[i] = files['file']\n",
    "    text = list(files['filtered_content'].split())\n",
    "    \n",
    "    for j,word in enumerate(text):\n",
    "        if word in posting:\n",
    "            if posting[word][-1]!=i:\n",
    "                posting[word].append(i)\n",
    "        else:\n",
    "            posting[word] = [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting terms in Alphabetical order\n",
    "\n",
    "terms = list(posting.keys())\n",
    "terms.sort()\n",
    "\n",
    "Index ={}\n",
    "for words in terms:\n",
    "    Index[words] = posting[words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 151164 terms from 1133 documents\n"
     ]
    }
   ],
   "source": [
    "print(\"Indexed \"+str(len(terms))+\" terms from \"+str(len(docs))+\" documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(Index,open('./pickle_files/index.pkl','wb'))\n",
    "pkl.dump(docs,open('./pickle_files/doc_id.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f1cbb85fbb159a91b512923319bfb5d4c6de1269d10ca612a23b6e07a28361c8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
